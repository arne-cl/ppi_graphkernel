"""
  Program:    Classes for working with parse graphs
  Date:       Jan. 31, 2008
  Author:     Jari Bjorne

  Description: This file contains classes and functions for working with
  sentence parse graphs. A parse graph can be created from interaction xml.
  The nodes can be modified and assigned attributes like weight, and the
  result can be converted into an adjacency matrix. The parse graph can
  also be used to generate different paths between its tokens.

  Status: All classes and methods should be working.
"""

import sys
import types
import time

import numpy

from ppi_graphkernel import Dijkstra
from ppi_graphkernel.utils import Range

def splitPathStyles(styleString):
    """
    splitPathStyles splits a style string into a list of dictionaries.

    styleString is a comma-separated list of styles.
    Styles are in the format style:length:directed:weight, where weight
    is optional.

    Style can be either "binary" or "tertiary", length can be either
    "all" or "shortest", directed is either "directed" or "nondirected"
    and weight is a number. For example "binary:all:directed:0.3" and
    "tertiary:shortest:nondirected:0.9"
    """
    splits = styleString.split(",")
    styles = []
    for split in splits:
        styleSplits = split.split(":")
        assert styleSplits[0] in ("binary", "all_tertiary", "closest_tertiary", "root")
        assert styleSplits[1] in ("all_shortest", "random_shortest", "all")
        assert styleSplits[2] in ("directed", "nondirected")

        style = {"weight": None}
        style["type"] = styleSplits[0]
        style["length"] = styleSplits[1] # lengths
        style["direction"] = styleSplits[2]
        if len(styleSplits) > 3:
            style["weight"] = float(styleSplits[3]) # weight
        styles.append(style)
    return styles


class DijkstraNode:
    def __init__(self):
        self.incoming = []
        self.outgoing = []


class DijkstraEdge:
    def __init__(self, fro=None, to=None):
        self.fro = fro
        self.to = to
        self.weight = 1


class ParseGraphNode(DijkstraNode):
    """
    Represents a single node (either token or dependency) in the parse
    graph or a path generated by a ParseGraph object.
    """
    paths = None # used during path generation

    def __init__(self, isDependency=False):
        self.isDependency = isDependency
        # token attributes
        self.pos = None
        self.text = None
        self.ppiText = None # added to adjacency matrix labels
        self.ppiPretag = None # added to adjacency matrix labels
        self.isPPIInteraction = False
        self.metamapCodes = []
        self.id = None
        self.charOffset = None
        self.dependencies = [] # all dependencies
        self.entities = [] # this token is part of these named entities
        self.interactionWords = [] # this token is part of these interaction words
        self.isOnShortestPath = False
        # dependency attributes
        self.dependencyType = None
        self.ppiType = None
        self.fro = None # added to adjacency matrix labels
        self.to = None

        self.disabled = False # used for speeding up path generation

        self.rootPaths = []

        DijkstraNode.__init__(self)

    def buildPathsToRoots(self, path=None):
        if path != None:
            #print "adding path to", self.id, self.text
            self.rootPaths.append(path + [self])
            #path = path[:]
        else:
            path = []
        #path.append(self)
        for dependency in self.dependencies:
            if dependency.to == self:
                if (not self in path) and (not dependency in path):
                    dependency.fro.buildPathsToRoots(path + [self, dependency])
    
    def buildPathsTo(self, targetId, impassableNodes=None):
        """ Returns all paths from this node to the target node
        """
        ParseGraphNode.paths = []
        if impassableNodes == None:
            ParseGraphNode.impassableNodes = []
        self.__buildPathsTo(targetId,[])
        newPaths = ParseGraphNode.paths
        ParseGraphNode.paths = None
        ParseGraphNode.impassableNodes = None
        return newPaths
    
    def __buildPathsTo(self, targetId, currentPath):
        """ Recursive method called by the public buildPathsTo
        """
        if self.id in ParseGraphNode.impassableNodes:
            return
        
        currentPath.append(self)
        if self.id == targetId and not currentPath[0].id == self.id:
            ParseGraphNode.paths.append(currentPath)
            return
        
        pathLength = len(currentPath)
        branch = False
        for dependency in self.dependencies:
            if (not dependency.disabled) and (not dependency in currentPath):
                if branch:
                    currentPath = currentPath[0:pathLength]
                currentPath.append(dependency)
                if dependency.fro == self:
                    dependency.to.__buildPathsTo(targetId, currentPath)
                else: 
                    assert(dependency.to == self)
                    dependency.fro.__buildPathsTo(targetId, currentPath)
                branch = True
    
    def setDistance(self, currentDistance):
        """ Recursive method called by ParseGraph.reduceWeightByDistance
        """
        assert(self.isDependency)
        for dependency in self.fro.dependencies + self.to.dependencies:
            assert(dependency.isDependency)
            if dependency == self:
                continue
            if dependency.weightDistance > currentDistance + 1:
                dependency.weightDistance = currentDistance + 1
                dependency.setDistance(currentDistance + 1)
    
    def toString(self, showPos=False, highlight=False):
        string = ""
        if self.isDependency:
            string = "<" + str(self.dependencyType) + ">"
        else:
            if showPos:
                string = "[" + self.pos + "]"
            else:
                string = "[" + self.text + "]"
        if highlight:
            string = "{" + string[1:-1] + "}"
        return string

class ParseGraph:
    """
    A ParseGraph-object consists of tokens and dependencies. A dependency connects
    two tokens with two edges (token->dependency->token, where -> = edge).
    """
    def __init__(self, tokenElements, dependencyElements, mergeDependencies=False):
        self.dijkstra = None
        self.tokensById, self.dependenciesById = self.buildParseGraph(tokenElements, dependencyElements, mergeDependencies)
    
    ###########################################################################
    # Construction and Conversion
    ###########################################################################

    def buildAdjacencyMatrix(self, floattype, directed=True, linearOrderWeight=0.9):
        """ Returns a Numpy-matrix
        """
        tokensById, dependenciesById = self.tokensById, self.dependenciesById
        #For each token, 2 nodes are allocated. For each dependency, one node is allocated
        node_count = 2*len(tokensById) + len(dependenciesById)
        # Make the adjacency matrix of the graph
        adjMatrix = numpy.mat(numpy.zeros((node_count,node_count), dtype = floattype))
        #A dictionary of labels is associated with each node
        labels = [set([]) for x in range(node_count)]
        #The word nodes have indices 0..2*len(tokens), the dependency nodes have the rest of the indices.
        dep_indices = range(2*len(tokensById), node_count)
        
        #For each dependency
        depKeys = dependenciesById.keys()
        depKeys.sort()
        for depKey, index in zip(depKeys, dep_indices):
            dep = dependenciesById[depKey]
            #Token1-dependency, and dependency-token2 weights are added
            adjMatrix[dep.fro.id-1, index] = dep.ppiWeight
            adjMatrix[index, dep.to.id-1] = dep.ppiWeight
            #For undirected graphs, the links would also go the other way
            if not directed:
                adjMatrix[dep.to.id-1, index] = dep.ppiWeight
                adjMatrix[index, dep.fro.id-1] = dep.ppiWeight
           
            if type(dep.ppiType) == types.ListType:
                for i in dep.ppiType:
                    labels[index].add(i)
            else:
                labels[index].add(dep.ppiType)
        #Add the linear order of the sentence to the matrix
        for i in range(len(tokensById),2*len(tokensById)-1):
            adjMatrix[i,i+1] = linearOrderWeight
            if not directed:
                adjMatrix[i+1,i] = linearOrderWeight
    
        #For each token
        for node in tokensById.values():
            index = node.id - 1
            if node.isOnShortestPath:
                labels[index].add("sp_"+node.ppiText)
                labels[index].add("sp_"+node.pos)
            else:
                labels[index].add(node.ppiText)
                labels[index].add(node.pos)
            for code in node.metamapCodes:
                labels[index].add(code)
            if node.isPPIInteraction:
                labels[index].add("1Nt3R4Ct")
            if node.ppiPretag != None:
                labels[len(tokensById)+index].add(node.ppiPretag+node.ppiText)
                labels[len(tokensById)+index].add(node.ppiPretag+node.pos)
                for code in node.metamapCodes:
                    labels[len(tokensById)+index].add(node.ppiPretag+code)
                if node.isPPIInteraction:
                    labels[len(tokensById)+index].add(node.ppiPretag+"1Nt3R4Ct")
        
        return adjMatrix, labels

    def buildParseGraph(self, tokenElements, dependencyElements, mergeDependencies=False):
        """ Returns dictionaries containing tokens and dependencies
        of the graph generated from ElementTree-elements.
        """
        #import networkx as NX
        #self.nXGraph = NX.Graph()
        
        tokensById = {}
        dependenciesById = {}
        for tokenElement in tokenElements:
            node = ParseGraphNode()
            node.id = int(tokenElement.attrib["id"].split("_")[1])
            node.pos = tokenElement.attrib["POS"]
            node.text = tokenElement.attrib["text"]
            charFrom, charTo = tokenElement.attrib["charOffset"].split("-")
            node.charOffset = (int(charFrom), int(charTo))
            tokensById[node.id] = node
            #self.nXGraph.add_node(node.id)
    
        #self.depByOrder = []
        dependencyIndex = len(tokensById) + 99
        if mergeDependencies:
            dependenciesByFroAndTo = {}
        for dependencyElement in dependencyElements:
            dependency = ParseGraphNode(True)
            dependency.dependencyType = dependencyElement.attrib["type"]
            dependency.fro = tokensById[int(dependencyElement.attrib["t1"].split("_")[1])]
            dependency.to = tokensById[int(dependencyElement.attrib["t2"].split("_")[1])]
            
            if mergeDependencies:
                key = (dependency.fro.id, dependency.to.id) #frozenset([dependency.fro.id, dependency.to.id])
                if dependenciesByFroAndTo.has_key(key):
                    if not type(dependenciesByFroAndTo[key].dependencyType) == types.ListType:
                        dependenciesByFroAndTo[key].dependencyType = [dependenciesByFroAndTo[key].dependencyType]
                    dependenciesByFroAndTo[key].dependencyType.append(dependency.dependencyType)
                else:
                    dependenciesByFroAndTo[key] = dependency
                    tokensById[dependency.fro.id].dependencies.append(dependency)
                    tokensById[dependency.to.id].dependencies.append(dependency)
                    dependency.id = dependencyIndex
                    assert( not dependenciesById.has_key(dependency.id) )
                    dependenciesById[dependency.id] = dependency
            else:
                tokensById[dependency.fro.id].dependencies.append(dependency)
                tokensById[dependency.to.id].dependencies.append(dependency)
                #dependenciesById["dep_" + str(dependencyIndex) + "-mt_" + str(dependency.fro.id) + "-" + dependency.dependencyType + "-mt_" + str(dependency.to.id)] = dependency
                #dependenciesById[dependencyIndex] = dependency
                dependency.id = dependencyIndex # (dependency.fro.id,dependency.to.id)
                assert( not dependenciesById.has_key(dependency.id) )
                dependenciesById[dependency.id] = dependency
            #self.depByOrder.append(dependency)
            #self.nXGraph.add_node(dependency.id)
            #self.nXGraph.add_edge((dependency.fro.id,dependency.id))
            #self.nXGraph.add_edge((dependency.id,dependency.to.id))
            dependencyIndex += 1
        
        return tokensById, dependenciesById

    def buildDijkstra(self):
        """ Initializes the graph structure used by Antti's Dijkstra.
        Called automatically when needed.
        """
        dijkstraNodes = self.tokensById.values() + self.dependenciesById.values()
        dijkstraEdges = []
        for node in self.dependenciesById.values():
            edgeIn = DijkstraEdge(node.fro, node)
            edgeOut = DijkstraEdge(node, node.to)
            node.incoming = [edgeIn]
            node.outgoing = [edgeOut]
            node.fro.outgoing.append(edgeIn)
            node.to.incoming.append(edgeOut)
        self.dijkstra = Dijkstra.Dijkstra(dijkstraNodes, dijkstraEdges)

    def buildPathsToRoots(self):
        count = 0
        keys = self.tokensById.keys()
        keys.sort()
        for key in keys:
            token = self.tokensById[key]
            if len(token.entities) > 0:
                token.buildPathsToRoots()
            count += 1
            
    ###########################################################################
    # Marking and manipulation of special tokens
    ###########################################################################
    
    def markBioInferInteractions(self, interactions):
        """ Marks tokens belonging to a BioInfer interaction
        """
        interactionTokens = []
        for interaction in interactions:
            offsets = []
            offsetStrings = interaction[3].split(",")
            for offsetString in offsetStrings:
                charFrom, charTo = offsetString.split("-")
                offset = (int(charFrom), int(charTo))
                offsets.append(offset)
            for k,v in self.tokensById.iteritems():
                for offset in offsets:
                    if Range.overlap(offset, v.charOffset):
                        v.interactionWords.append(interaction[4])
                        interactionTokens.append(v.id)
        return interactionTokens
    
    def markNamedEntities(self, entityElements):
        """ Marks tokens belonging to named entities
        """
        namedEntityTokens = []
        for entityElement in entityElements:
            offsets = []
            offsetStrings = entityElement.attrib["charOffset"].split(",")
            for offsetString in offsetStrings:
                charFrom, charTo = offsetString.split("-")
                offset = (int(charFrom), int(charTo))
                offsets.append(offset)
            for k,v in self.tokensById.iteritems():
                for offset in offsets:
                    if Range.overlap(offset, v.charOffset):
                        v.entities.append(entityElement.attrib["id"])
                        namedEntityTokens.append(v.id)
        return namedEntityTokens

    def getNamedEntityTokenIds(self, namedEntityIds):
        """ Returns the ids of all tokens in specified named entities
        """
        tokenIds = []
        for key, node in self.tokensById.iteritems():
            for id in namedEntityIds:
                if id in node.entities:
                    tokenIds.append(node.id)
        return tokenIds
    
    def getTokenIdsByText(self, texts, lookInsideNamedEntities=False):
        """ Returns the ids of all tokens whose text attribute can be
        found in the list texts. Can be used f.e. detecting interaction
        words.
        """
        matchingTokens = []
        for node in self.tokensById.values():
            if len(node.entities) > 0 and not lookInsideNamedEntities:
                continue
            if node.text.lower() in texts:
                matchingTokens.append(node.id)
            elif node.text.find("-") != -1: # For cases like actin-activation
                tempText = node.text.rsplit("-",1)[1]
                if tempText.lower() in texts:
                    matchingTokens.append(node.id)
        return matchingTokens
    
    def getBioInferInteractionTokenIds(self, interactionIds):
        """ Returns the ids of all tokens in specified interaction words
        """
        tokenIds = []
        for key, node in self.tokensById.iteritems():
            for id in interactionIds:
                if id in node.interactionWords:
                    tokenIds.append(node.id)
        return tokenIds
    
    ###########################################################################
    # Path Construction
    ###########################################################################
    
    def buildShortestPaths(self, startTokenId, endTokenId, all=False, directed=False):
        """ Build shortest paths using Dijkstra's algorithm
        """
        if self.dijkstra == None:
            self.buildDijkstra()
        self.dijkstra.dijkstrate(self.tokensById[startTokenId], directed)
        if all:
            return self.dijkstra.getAllPaths(self.tokensById[endTokenId])
        else:
            return [self.dijkstra.getPath(self.tokensById[endTokenId])]

    def buildCommonRootPaths(self, startTokens, endTokens, interactionWords=None):
        paths = []
        for token in self.tokensById.values():
            if interactionWords == None or token.text in interactionWords:
                for i in range(len(token.rootPaths)-1):
                    for j in range(i+1,len(token.rootPaths)):
                        if (token.rootPaths[i][0].id in startTokens and token.rootPaths[j][0].id in endTokens) \
                        or (token.rootPaths[i][0].id in endTokens and token.rootPaths[j][0].id in startTokens):
                            if token.rootPaths[i][0].id < token.rootPaths[j][0].id:
                                reversed = token.rootPaths[j][:]
                                reversed.reverse()
                                joinedPath = token.rootPaths[i][:-1] + reversed
                                rootIndex = len(token.rootPaths[i])-1
                            else:
                                reversed = token.rootPaths[i][:]
                                reversed.reverse()
                                joinedPath = token.rootPaths[j][:-1] + reversed
                                rootIndex = len(token.rootPaths[j])-1
                            paths.append( (joinedPath, rootIndex) )
        return paths

    def buildTertiaryPaths(self, startTokens, midTokens, endTokens, useClosestMidToken=False, length="random_shortest", directed=False, timeout=None):
        """ Returns all paths from all startTokens to all endTokens through
        all midTokens. Return value is a list of tuples (A,B) where A is a
        list of ParseGraphNode-objects and B is the index of the interaction
        word in A.
        """
        if useClosestMidToken:
            allMidTokens = midTokens[:]
        
        paths = []
        i = j = 0
        startTime = -1
        while i < len(startTokens):
            while j < len(endTokens):
                if timeout != None:
                    if startTime == -1:
                        startTime = time.time()
                    if time.time() - startTime > timeout:
                        if length != "all_shortest":
                            print >> sys.stderr, "Path generation timed out, switching to all_shortest"
                            length = "all_shortest"
                            startTime = time.time()
                            i = 0
                            j = 0
                        else:
                            print >> sys.stderr, "Path generation timed out, interrupting path generation"
                            return paths
                
                tokenId = startTokens[i]
                tokenId2 = endTokens[j]
                if True: #tokenId2 != tokenId:
                    if tokenId > tokenId2:
                        tokenId, tokenId2 = tokenId2, tokenId

                    # Optionally build paths only to the closest midToken
                    if useClosestMidToken:
                        midTokens = []
                        minDistance = 9999
                        for midToken in allMidTokens:
                            distance = abs(tokenId - midToken) + abs(tokenId2 - midToken)
                            if distance <= minDistance:
                                if distance < minDistance:
                                    midTokens = []
                                    minDistance = distance
                                midTokens.append(midToken)
                    
                    for tokenIdMid in midTokens:
                        #print "start"
                        # Build sections from token 1 to interaction word
                        if length == "random_shortest":
                            startSections = self.buildShortestPaths(tokenIdMid, tokenId, False, directed)
                        elif length == "all_shortest":
                            startSections = self.buildShortestPaths(tokenIdMid, tokenId, True, directed)
                        elif length == "all":
                            #token = self.tokensById[tokenId]
                            midToken = self.tokensById[tokenIdMid]
                            startSections = midToken.buildPathsTo(tokenIds)
                        else:
                            print >> sys.stderr, "Unknown path length in ParseGraph.buildTertiaryPaths:", length
                            sys.exit(0)
                        if len(startSections) == 0:
                            continue
                        for section in startSections:
                            section.reverse()
                        # Build sections from interaction word to token 2
                        if length == "random_shortest":
                            endSections = self.buildShortestPaths(tokenIdMid, tokenId2, False, directed)
                        elif length == "all_shortest":
                            endSections = self.buildShortestPaths(tokenIdMid, tokenId2, True, directed)
                        elif length == "all":
                            midToken = self.tokensById[tokenIdMid]
                            endSections = midToken.buildPathsTo(tokenId2)
                        if len(endSections) == 0:
                            continue
                        # Connect sections
                        #print "connect"
                        for startSection in startSections:
                            for endSection in endSections:
                                if len(startSection) == 0 or len(endSection) == 0:
                                    continue 
                                path = startSection + endSection[1:]
                                interactionWordIndex = len(startSection)-1
                                paths.append( (path, interactionWordIndex) )
                j += 1
            i += 1
            j = 0
        return paths

    def buildBinaryPaths(self, startTokens, endTokens, length="random_shortest", directed=False, timeout=None):
        """ Returns all paths from all startTokens to all endTokens.
        Return value is a list of lists of ParseGraphNode-objects.
        """
        paths = []
        i = j = 0
        startTime = -1
        while i < len(startTokens):
            while j < len(endTokens):
                if timeout != None:
                    if startTime == -1:
                        startTime = time.time()
                    if time.time() - startTime > timeout:
                        if length != "all_shortest":
                            print >> sys.stderr, "Path generation timed out, switching to all_shortest"
                            length = "all_shortest"
                            startTime = time.time()
                            i = 0
                            j = 0
                        else:
                            print >> sys.stderr, "Path generation timed out, interrupting path generation"
                            return paths

                tokenId = startTokens[i]
                tokenId2 = endTokens[j]
                if tokenId > tokenId2:
                    tokenId, tokenId2 = tokenId2, tokenId
                #print "Tokens:", tokenId, tokenId2
                if length == "random_shortest":
                    paths.extend(self.buildShortestPaths(tokenId, tokenId2, False, directed))
                elif length == "all_shortest":
                    paths.extend(self.buildShortestPaths(tokenId, tokenId2, True, directed))
                elif length == "all":
                    token = self.tokensById[tokenId]
                    token2 = self.tokensById[tokenId2]
                    #print "token1 pos/text:", token.pos, token.text
                    #print "token2 pos/text:", token2.pos, token2.text
                    paths.extend(token.buildPathsTo(tokenId2))
                else:
                    print >> sys.stderr, "Unknown path length in ParseGraph.buildBinaryPaths"
                j += 1
            i += 1
            j = 0
        return paths
    
    def buildBinaryPathsBetweenAll(self, tokensToConnect):
        """ Returns all paths between all specified tokens. Paths
        are directed so that the first token of the path is always
        before the last token of the path in the token order.
        """
        paths = []
        for tokenId in tokensToConnect:
            token = self.tokensById[tokenId]
            #targetTokens = []
            for tokenId2 in tokensToConnect:
                if tokenId2 != tokenId:
                    if tokenId < tokenId2:
                        #targetTokens.append(tokenId2)
                        paths.extend(token.buildPathsTo(tokenId2))
        return paths

    ###########################################################################
    # Dependency Weights
    ###########################################################################
    
    def setAllDependencyWeights(self, weight):
        """ All weights are set to the given value
        """
        for node in self.dependenciesById.values():
            node.ppiWeight = weight
    
    def setDependencyWeightsByPath(self, paths, weight):
        """ The weights of all dependencies in specified paths are set to the
        given value
        """
        for path in paths:
            for node in path:
                if node.isDependency:
                    node.ppiWeight = weight
                    
    def reduceWeightByDistance(self, zeroDistanceThreshold = 0.9, reduceFactor = 0.5):
        """ Reduces the weight of dependencies based on their distance
        from the nearest dependency whose weight is >= the threshold.
        """
        zeroDistanceDependencies = []
        # Initialize distances to a large number
        for node in self.dependenciesById.values():
            node.weightDistance = 99999999
            if node.ppiWeight >= zeroDistanceThreshold:
                node.weightDistance = 0
                zeroDistanceDependencies.append(node)
            for i in node.fro.dependencies:
                assert(i in self.dependenciesById.values())
            for i in node.to.dependencies:
                assert(i in self.dependenciesById.values())
        
        # Cannot reduce weight if no node is over threshold
        if len(zeroDistanceDependencies) == 0:
            return
        
        # Calculate distances
        for node in zeroDistanceDependencies:
            node.setDistance(0)
        
        # Reduce weight
        for node in self.dependenciesById.values():
            node.ppiWeight *= pow(reduceFactor, max(node.weightDistance - 1, 0))

    ###########################################################################
    # PPI-label creation and modification
    ###########################################################################
    
    def addMetamapCodes(self, codesByTokenId):
        for k,v in self.tokensById.iteritems():
            if codesByTokenId.has_key(k):
                v.metamapCodes = codesByTokenId[k]
    
    def ppiTextFromOriginalText(self):
        """ Sets the ppiText of all tokens to their original text
        """
        for token in self.tokensById.values():
            token.ppiText = token.text

    def maskNames(self, e1Id, e2Id):
        """ Sets the ppiText of all tokens based on the text of the token, 
        and masks the text of all named entities and the proteins in the 
        pair. 
        """
        for token in self.tokensById.values():
            #Give different labels to tokens belonging to named entities
            if e1Id in token.entities:
                token.ppiText = "PROTEIN1"
            elif e2Id in token.entities:
                token.ppiText = "PROTEIN2"
            elif len(token.entities) > 0: # token belongs to at least one named entity
                token.ppiText = "PROTEIN_X"
            #else: 
            #    token.ppiText = token.text
    
    def addPositionTags(self, entity1TokenIds, entity2TokenIds):
        """ Sets a prefix to the tokens ppiText based on their linear
        order in the sentence.
        """
        entity1FirstTokenId = min(entity1TokenIds)
        entity2LastTokenId = max(entity2TokenIds)
        for token in self.tokensById.values():
            pretag = "$$"
            assert(token.ppiText != None)
            if not token.ppiText in ["PROTEIN1", "PROTEIN2"]:
                if token.id < entity1FirstTokenId:
                    pretag = "$B$"
                elif token.id > entity2LastTokenId:
                    pretag = "$A$"
            token.ppiPretag = pretag
    
    def setPPIPrefixForDependencies(self, prefix, threshold):
        """ Sets the dependencies ppiType to their dependencyType, 
        and adds a prefix if their weight is over a given threshold 
        """
        for dependency in self.dependenciesById.values():
            if dependency.ppiWeight >= threshold:
                dependency.to.isOnShortestPath = True
                dependency.fro.isOnShortestPath = True
                if type(dependency.dependencyType) == types.ListType:
                    dependency.ppiType = []
                    for i in range(len(dependency.dependencyType)):
                        dependency.ppiType.append(prefix + dependency.dependencyType[i])
                else:
                    dependency.ppiType = prefix + dependency.dependencyType
            else:
                if type(dependency.dependencyType) == types.ListType:
                    dependency.ppiType = []
                    for i in range(len(dependency.dependencyType)):
                        dependency.ppiType.append(dependency.dependencyType[i])
                else:
                    dependency.ppiType = dependency.dependencyType
    
    def setPPIInteractionWords(self, paths):
        for path in paths:
            path[0][path[1]].isPPIInteraction = True

###############################################################################
# Path functions
###############################################################################

def removeIntraEntityPaths(paths):
    """ Returns a list with paths starting and ending within the same named
    entity removed. 
    """
    pathsToKeep = []
    for path in paths:
        keep = True
        for entity1 in path[0].entities:
            for entity2 in path[-1].entities:
                if entity1 == entity2:
                    keep = False
                    break
            if keep == False:
                break
        if keep:
            pathsToKeep.append(path)
    return pathsToKeep

def getPathsByLength(paths, threshold):
    pathsToKeep = []
    for path in paths:
        if len(path[0]) <= threshold:
            pathsToKeep.append(path)
    return pathsToKeep

def getShortestPaths(paths):
    """ Returns a list containing only the shortest paths. The list may contain
    several shorters paths with the same length. 
    """
    shortestPaths = []
    shortestLength = 99999
    for path in paths:
        if len(path) < shortestLength:
            shortestLength = len(path)
    for path in paths:
        if len(path) == shortestLength:
            shortestPaths.append(path)
    return shortestPaths

def getShortestTertiaryPaths():
    """ Returns a list containing only the shortest paths. The list may contain
    several shorters paths with the same length. 
    """
    shortestPaths = []
    shortestLength = 99999
    for path in paths:
        if len(path[0]) < shortestLength:
            shortestLength = len(path[0])
    for path in paths:
        if len(path[0]) == shortestLength:
            shortestPaths.append(path)
    return shortestPaths

# same as previous path generator    
def buildPathsBetweenNamedEntities(namedEntityElements, tokenElements, dependencyElements):
    tokensById = buildParseGraph(tokenElements, dependencyElements)
    namedEntityNodeIds = markNamedEntities(namedEntityElements, tokensById)
    binaryPaths = buildBinaryPaths(namedEntityNodeIds, tokensById)
    return removeIntraEntityPaths(binaryPaths)
